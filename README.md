# Linear Regression:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Linear Regression is a Statistical model used to predict the relation between independent and dependent variables.

### Regression Equation:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Simplest form of a simple linear regression equation with one dependent and one independent variable is presented by:

<div align="center"> Y = mX + C </div>

_Where,_ <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _Y = Dependent variable_  <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _X = Independent variable_  <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _m = Slop of the line_  <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _C = Coefficient of the line_  <br />

![Line Graph](https://github.com/prnvvj/Linear-Regression/blob/main/PNG/equation-of-a-straight-line.png)


_Here,_ <br />
![Slope of Line](https://github.com/prnvvj/Linear-Regression/blob/main/PNG/slop%20of%20line.PNG)

![error indication](https://github.com/prnvvj/Linear-Regression/blob/main/PNG/error-indication.PNG)
- Here the Blue points represents the original data points and the Red points represents the predicted Y values.
- Distnace between the actual and predicted values are known ad error or residuals.
- The best fit line should have the least number of square of these errors, also known as e-square.

##### Finding the Best Fit Line:
**Minimizing the Errors:** <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There are lot of ways to minimize the distance between the line and the data points like _**"Sum of Squared Errors", "Sum of Absolute Errors", "Root Mean Square Errors"**_, etc.
_We keep moving the line through the data points to make sure the best fit line has the least square distance between the data points and the regression line._

